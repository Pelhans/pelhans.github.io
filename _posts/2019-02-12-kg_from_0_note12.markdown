---
layout:     post
title:      "百科知识图谱构建（四）"
subtitle:   "基于Silk的知识融合"
date:       2019-02-12 00:15:18
author:     "Pelhans"
header-img: "img/kg_bg.jpg"
header-mask: 0.3 
catalog:    true
tags:
    - Knowledge Graph
---


> 目前为止我们已经从百度百科获取了三元组 62,857,364个，互动百科 65,738,654个，词条每个都是400多万个。由于都是百科类，因此有大量的重复词条。现在我们使用 Silk 工具将他们在实体层次进行融合并给出 <owl:sameAs> 关系。

* TOC
{:toc}

# 简介

[silk](https://github.com/silk-framework/silk) 是一个集成异构数据源的开源框架。编程语言为Python。其特点为：

* 提供了专门的 Silk-LSL 语言来进行具体处理。    
* 提供图形化用户界面- Silk Workbench，用户可以很方便的进行记录链接。

Silk 的整体框架如下图所示：

![](/img/in-post/kg_from_0/silk_arc.png)

包含以下几大块：

* 预处理：会将索引的结果排名前N的记录下来进行作为候选对，进行下一步更精准的匹配(损失精度)。    
* 相似度计算：里面包含了很多相似度计算的方法。    
* 过滤： 过滤掉相似度小于给定阈值的记录对。

# Silk 的安装

Silk 的安装比较容易，基本上安装github的链接一步步来就行了。我使用的是 Ubuntu 16，这里记录下我的安装步骤。

* 安装 JDK 8

```python
sudo apt-get install openjdk-8-jdk openjdk-8-source
```

* 安装 sbt

```python
echo "deb https://dl.bintray.com/sbt/debian /" | sudo tee -a /etc/apt/sources.list.d/sbt.list ;
sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 2EE0EA64E40A89B84B2DF73499E82A75642AC823;
sudo apt-get update;
sudo apt-get install sbt
```

* 安装 Yarn(>=1.3)

```python
curl -sL https://deb.nodesource.com/setup_11.x | sudo -E bash -;
sudo apt-get install -y nodejs;
curl -sS https://dl.yarnpkg.com/debian/pubkey.gpg | sudo apt-key add -;
echo "deb https://dl.yarnpkg.com/debian/ stable main" | sudo tee /etc/apt/sources.list.d/yarn.list;
sudo apt-get update && sudo apt-get install yarn;
```

尝试 yarn --version 命令看看是否安装成功。

# 运行 Silk Workbench

首先去 github 上将 silk 库 clone 下来：

"""python
git clone https://github.com/silk-framework/silk.git
"""

进入该目录，而后运行 ```./sbt "project workbench" run```命令，然后程序会开始编译，这一步会比较慢，等提示Server started 后，就可以在浏览器端打开 localhost:9000 进行访问了。

# Silk 的使用说明

关于 Silk 的详细介绍都在[官方文档](https://github.com/silk-framework/silk/tree/develop/doc)中，感兴趣的可以进行查看。我这里对 Workbench 给出个简短的介绍。

## Workbench 概览

Workbench 引导用户完成创建链接任务的过程，以便链接两个数据源。 它提供以下组件：

* 工作区(workspace) 浏览器：允许用户浏览工作区中的项目。 链接任务可以从项目加载并稍后返回。    
* 链接规则编辑器(Linkage Rule Editor)：一种图形编辑器，使用户可以轻松创建和编辑链接规则。 窗口小部件将在树视图中显示当前链接规范，同时允许使用拖放进行编辑。    
* 评估(Evaluation)：允许用户执行当前的链接规则。 在即时生成链接时会显示这些链接。 生成的链接参考链接集未指定其正确性，用户可以确认或拒绝其正确性。 用户可以请求关于如何组成特定链接的相似性得分的详细摘要。

创建新链接任务的典型工作流程包括：

![](/img/in-post/kg_from_0/silk_linking_workflow.png)

1) 在执行实际匹配之前，需要构建一个链接规则，该规则指定如何比较两个实体的等价性。 链接规则可以由人类专家根据要匹配的数据源创建。    
2) 执行链接规则，产生一组链接。    
3) 评估步骤的目的是测量实体匹配任务的成功率并在生成的链接中查找潜在的错误。 实体匹配任务的成功可以通过将生成的链接与由一组参考链接组成的金标准进行比较来确定。 一组参考链接包含正参考链接，其标识已知匹配的实体对和负参考链接，其标识已知不匹配的对。 如果没有参考链接，则可以由确认或拒绝许多链接的人类专家生成 gold 标准。

## 链接规则编辑器

链接规则编辑器允许用户以图形方式编辑链接规则。 通过拖放规则元素将链接规则创建为运算符树。编辑分为两部分：

* 左窗格包含给定数据集和限制的最常用属性路径。 它还包含所有可用运算符转换，比较器和聚合器的列表作为可拖动元素。    
* 右侧部分（编辑器窗格）允许通过组合所选元素来绘制流程图。    

![](/img/in-post/kg_from_0/silk_linkageRuleEditor.png)

## 编辑 

* 将元素从左窗格拖到编辑器窗格。    
* 通过从元素端点和元素端点（元素框左侧和右侧的点）绘制连接来连接元素。    
* 通过连接元素来构建流程图，以单个元素（比较或聚合）结束。

编辑器将在绘制新连接线时通过突出显示可连接元素来指导用户构建流程图。

## 属性路径

要链接的两个数据源的属性路径将加载到左窗格中，并按其频率在数据源中的顺序添加。 用户还可以通过将（自定义路径）元素拖到编辑器窗格并编辑路径来添加自定义路径。

## 操作符

以下运算符窗格显示在属性路径下方：

* Transformations    
* Comparisons    
* Aggregations

将鼠标悬停在操作元素上将显示有关它们的更多信息。

## 参考链接

参考链接（在记录链接中通常称为 gold 集）是一组链接，其正确性已被用户确认或拒绝。 参考链接可用于评估链接规则的完整性和正确性。

我们区分正面和负面的参考链接：

* 正参考链接代表最终匹配    
* 负参考链接代表确定的不匹配。

# Silk 实战

这里我采用两种格式数据分别进行融合：

* N-triples 文件    
* SPARQL 端口

## 基于 N-triples 文件

N-triples 文件就是我们在 d2rq 那步得到的 .nt 文件。Silk 这里比较麻烦的是(也有可能我没弄明白)不支持大的 N-triples 文件，否则会报错。因此这里实验只用几兆的 nt 文件，包含 1000 个三元组。

[三元组文件下载 百度网盘 提取码 wn1f](https://pan.baidu.com/s/1ZBuqxWEJU4uDwrztyIujSw)

### 项目的建立

在开启 silk 服务后，在浏览器端打开 http://localhost:9000，进入workspace 页面。点击 NEW project 按钮创建新项目。可以看到新项目包含 Datasets、Transform Tasks、Linking Tasks、Workflows、Others几项。

点击项目名称后面的 Prefixes 按钮，设置 Prefixe：

* 点击加号按钮，在出现的框中填入以下两项    
    * hudong: http://www.kghudong.com#
    * baidu: http://www.kgbaidu.com#    
* 点击 SAVE PREFIXES 按钮保存操作

点击项目名称后的 Resource 按钮，在这里我们可以添加或删除项目所使用的数据源。点击 UPLOAD LOCAL 下的 Browse 选项选中刚刚下载的 nt 文件，而后点击上传将两个 nt 文件都传上去。而后再点击 DEFINE OUTPUT 选项，在下面的Name中填写想输出数据文件的名字，如baike_merge.nt，点击CREATE 完成文件的创建。

### 创建数据集

点击 Datasets 后的 Add 按钮，在弹出的框中填写如下信息：

* 点击 Resource Type 选择数据类型，这里用的是三元组，因此选择 RDF file。    
* 填写 Name，如果是baidu_test.nt 那就写 baidu_test，hudong_test.nt 的就写 hudong_test，输出文件那个就写 output。    
* file 那里你点击一下会出现刚刚在 Resource 里添加的文件列表，选择对应的 nt 文件。    
* format 这里填写 N-Triples    
* 点击 SAVE 进行保存    

现在应该有三个数据集-baidu_test、hudong_test、output。

### 建立 Linking Tasks 

点击 Linking Tasks 后的Add按钮，建立链接任务。在弹出的框中，填写如下信息：

* 在 Name 那里填入任务名称，如 baike_test    
* Source Dataset 那里选择刚刚建立的 baidu_test    
* Target Dataset 那里填入刚刚建立的 hudong_test    
* output 那里填入 output    
* 点击 OK 完成创建

### 编辑链接规则

点击 baike_test 后的 Open 按钮进入 链接编辑界面。可以看到整个界面被分成两部分，左侧包含一系列的属性路径，右侧是编辑器窗格，允许我们来对属性路径进行组合。

首先在Source Path 里找到 baidu:lemmas_title 这行，将它拖拽到右侧窗格中，在Target path 里找到 hudong_lemmas_title 这行，也拖拽到右侧窗格中。将两个上下放置，像这样

![](/img/in-post/kg_from_0/silk_editor_0.png)

我们可以看到，接下来我们将 title 里面的字母全部转换为小写来统一格式。因此我们去左侧窗格的 Transformations 里找到 Lower case 这行，拽出来，放到 baidu:lemmas_title 和 hudong:lemmas_title 后面。现在整体长这样

![](/img/in-post/kg_from_0/silk_editor_1.png)

可以看到现在有四个框框，每个后面都有一个蓝色的圆点。点击 baidu:lemmas_title 后的圆点，拖拽鼠标将看到一个箭头，移动鼠标到 lower case 前面的圆点上则建立一个链接。hudong 那个也这么做，现在变成这样

![](/img/in-post/kg_from_0/silk_editor_2.png)

格式统一之后，我们采用 Levenshtein 距离来判断两个title 是不是相似的。因此去左侧窗格中的 Comparators 中找到 Levenshtein distance 这行，拖拽出来到右侧，并建立它与两个 lowerCase 框间的链接。

![](/img/in-post/kg_from_0/silk_editor_3.png)

现在一个简单的链接规则就建立完毕了。

### 评估

点击最上方的 EVALUATE 按钮，进入评估界面，在这里你可以判断链接结果是否正确并标记正负例。正负例可以用来计算准确率等一系列信息。

点击页面上方的运行按钮，可以看到程序正在运行，等程序运行完毕后，将出现以下界面：

![](/img/in-post/kg_from_0/silk_editor_4.png)

随意点击一行可以看到链接的详细信息。以第一个为例，可以看到 source 的 标题名称是上海，Target 的也是上海，两个确实是一样的。此时我们可以在 Correct 那列将问好改为对号。若标记结果错误那么就选择×，不确定则保持不动。

标记结束后，进入 REFERENCE LINKS 按钮，就可以看到我们刚刚标记的正例、负例和未标记部分。

### 运行

想直接大规模运行的话，进入 EXECUTE 页面，点击运行开始链接。等运行结束后，点击下载按钮下载输出文件。打开文件如下图所示：

![](/img/in-post/kg_from_0/silk_editor_5.png)

## 数据格式为 SPARQL 端口

前面说过对于 NT 格式的，silk支持的数据很小，所以对于规模大一些的只能采用 SPARQL Endpoint 的形式。和前面的主要区别是：

* Resource 那里不用添加输入 nt 文件了    
* 创建dataset 时的区别：
    * 创建 dataset 时，Resource Type 选择 SPARQL endpoint(remote)    
    * SPARQL 的访问我用的是 Fuseki作为服务器。    
    * endpoint URI 填写 http://localhost:3030/kg_baidu/sparql 。其中 kg_baidu 这个是 Fuseki 服务器中的数据库的名称。

关于 Fuseki 的使用请见上一篇教程[Jena的使用及简单SPARQL查询](http://pelhans.com/2019/02/11/kg_from_0_note11/)

创建好数据集后，其他的和之前的都一样。这里我遇到的问题是，当采用全部数据时(baidu 和 hudong 都是 6000多万时)，编辑窗口的属性路径加载不出来，会卡死，然后提示 JAVA heap 错误。还在摸索中。。。
